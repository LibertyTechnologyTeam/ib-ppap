name: Project Influence  Schedule Save Crawler data
on:
  workflow_dispatch:
    inputs:
      reason:
        description: "Fill reason here!!!!!!"
        required: false

jobs:
  get-profile-data:
    name: Get Profile Input Data
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.generate-cache-key.outputs.key }}
    steps:
      - name: Clone repository
        uses: actions/checkout@v3
        with:
          repository: "InfluenceBooking/crawler"
          token: ${{ secrets.GH_PAT }}
          ref: "main"
      # Generate a unique cache key
      - name: Generate cache key
        id: generate-cache-key
        run: |
          echo "key=${{ runner.os }}-crawler-data-${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20.10.0"
      - name: Install dependencies
        run: |
          npm install
      - name: Run script
        run: |
          echo "API_INFLUENCERS_URL=https://api-dev.theinfluence.ai" >> .env
          node --no-warnings ./src/write-input-data.js

      - name: Cache crawler data
        uses: actions/cache@v3
        with:
          path: |
            input_influencers.json
          key: ${{ steps.generate-cache-key.outputs.key }}
          restore-keys: ${{ runner.os }}-crawler-data-

  crawl-profiles:
    needs: get-profile-data
    runs-on: ubuntu-latest
    name: Crawl Social Profiles
    strategy:
      # matrix:
      #   platform: ["facebook", "instagram", "tiktok", "youtube"]
      #   include:
      #     - platform: facebook
      #       script: ./src/crawl-fb-profile.js
      #     - platform: instagram
      #       script: ./src/crawl-ig-profile.js
      #     - platform: tiktok
      #       script: ./src/crawl-tt-profile.js
      #     - platform: youtube
      #       script: ./src/crawl-yt-profile.js
      matrix:
        platform: ["facebook", "instagram", "tiktok", "youtube"]
        version: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
        region: ["us-east", "us-west", "eu-central", "ap-southeast"]
      # Allow all matrix jobs to continue even if one fails
      fail-fast: false
    steps:
      - name: Clone repository
        uses: actions/checkout@v3
        with:
          repository: "InfluenceBooking/crawler"
          token: ${{ secrets.GH_PAT }}
          ref: "main"
      - name: Get cache key
        id: get-cache-key
        run: |
          echo "cache-key=${{ needs.get-profile-data.outputs.cache-key }}" >> $GITHUB_OUTPUT

      # - name: Wait for input data
      #   uses: fountainhead/action-wait-for-check@v1.1.0
      #   with:
      #     token: ${{ secrets.GITHUB_TOKEN }}
      #     checkName: get-profile-data
      #     ref: ${{ github.sha }}

      - name: Restore crawler data
        uses: actions/cache@v3
        with:
          path: |
            input_influencers.json
          key: ${{ needs.get-profile-data.outputs.cache-key }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20.10.0"

      - name: Install dependencies
        run: npm install

      - name: Run script
        run: |
          echo "platform=${{ matrix.platform }}" 
          echo "version=${{ matrix.version }}" 
          echo "region=${{ matrix.region }}"
          echo "import { writeOutputData } from "./src/write-output-data.js"; writeOutputData("${{ matrix.platform }}", ${{ matrix.version }}, "${{ matrix.region }}");"
